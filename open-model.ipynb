{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.keras\nimport pandas as pd\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\nimport os\nimport skimage\nfrom skimage import io\nimport seaborn as sn\n\n\n# Seed\nSEED = 2727\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\n%matplotlib inline\n\n# Autocompletion\n%config Completer.use_jedi = False","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:23:25.739709Z","iopub.execute_input":"2022-07-10T14:23:25.740125Z","iopub.status.idle":"2022-07-10T14:23:34.71953Z","shell.execute_reply.started":"2022-07-10T14:23:25.740049Z","shell.execute_reply":"2022-07-10T14:23:34.71809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Architecture\npath_train = \"ships_data/train\"\npath_test = \"ships_data/test\"\nsubmission_file = \"ships_competition.npz\"","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:23:34.724476Z","iopub.execute_input":"2022-07-10T14:23:34.725947Z","iopub.status.idle":"2022-07-10T14:23:34.733875Z","shell.execute_reply.started":"2022-07-10T14:23:34.7259Z","shell.execute_reply":"2022-07-10T14:23:34.730771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf ships_data\n!tar xzf /kaggle/input/navire-2022-libre/ships.tgz\n!ls\n!ls ships32\n!mkdir ships_data\n!mv ships32 ships_data/train\n!mkdir ships_data/test\n!ls\n!ls ships_data\n!ls ships_data/train","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:23:34.739405Z","iopub.execute_input":"2022-07-10T14:23:34.740172Z","iopub.status.idle":"2022-07-10T14:23:45.921011Z","shell.execute_reply.started":"2022-07-10T14:23:34.740106Z","shell.execute_reply":"2022-07-10T14:23:45.919375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Get all the data and clean it (no black and white data otherwise it will break). As it is just some pictures, I delete them instead of coloring them myself.","metadata":{}},{"cell_type":"code","source":"def is_rgb_shape(im):\n    return len(im.shape) == 3 and im.shape[2] == 3\n\ndef get_info_clean_data(path):\n    \"\"\"\n    Load data from a directory\n    Get info of the data\n    Clean the data if necessary\n    \n    Return:\n        * A list of images\n        * A list of labels corresponding to the list of images\n        * A dataframe describing the images\n        * A map of label to class/category name\n    \"\"\"\n    label_to_category = dict()\n\n    labels = []\n    imgs = []\n    info = []\n\n    for curr_label, dirname in enumerate(np.sort(os.listdir(path))):\n        label_to_category[curr_label] = dirname\n\n        dirname = os.path.join(path, dirname)\n        for filename in os.listdir(dirname):\n            filename = os.path.join(dirname, filename)\n\n            img = skimage.io.imread(filename)\n            # L'image n'est pas rgb donc non ajout√©e (sinon ca casse tout)\n            if not is_rgb_shape(img):\n                os.remove(filename)\n                continue\n\n            imgs.append(img)\n            info.append([filename, curr_label, img.shape[0], img.shape[1], img.dtype])\n            labels.append(curr_label)\n\n    labels = np.array(labels)\n    df_input = pd.DataFrame(info, columns=[\"filename\", \"category\", \"width\", \"height\", \"dtype\"])\n    return np.array(imgs), labels, df_input, label_to_category","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:23:45.925639Z","iopub.execute_input":"2022-07-10T14:23:45.926789Z","iopub.status.idle":"2022-07-10T14:23:45.940585Z","shell.execute_reply.started":"2022-07-10T14:23:45.926741Z","shell.execute_reply":"2022-07-10T14:23:45.939091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgs, labels, df_input, label_to_category = get_info_clean_data(path_train)\n\nlabel_to_category","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:23:45.942242Z","iopub.execute_input":"2022-07-10T14:23:45.94316Z","iopub.status.idle":"2022-07-10T14:24:19.819238Z","shell.execute_reply.started":"2022-07-10T14:23:45.943088Z","shell.execute_reply":"2022-07-10T14:24:19.81754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can already notice that images seem to have the same shapes. But let's make sure of it by diving deeper in the metadata of the input.","metadata":{}},{"cell_type":"code","source":"df_input","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:24:19.821385Z","iopub.execute_input":"2022-07-10T14:24:19.822253Z","iopub.status.idle":"2022-07-10T14:24:19.853348Z","shell.execute_reply.started":"2022-07-10T14:24:19.822203Z","shell.execute_reply":"2022-07-10T14:24:19.852182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"some pictures to see if it works and what they look like (the pictures are really small ... I have some difficulties to recognize a boat on some of them).","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nnb_image_row = 5\nfor i in range(len(label_to_category)):\n    plt.subplot(3, 5, i + 1)\n    plt.title(label_to_category[i])\n    plt.imshow(imgs[np.argmax(labels==i)])\n    plt.axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:24:19.855006Z","iopub.execute_input":"2022-07-10T14:24:19.855591Z","iopub.status.idle":"2022-07-10T14:24:20.48158Z","shell.execute_reply.started":"2022-07-10T14:24:19.855508Z","shell.execute_reply":"2022-07-10T14:24:20.480219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Number of images with a different width:\", len(df_input.width[df_input.width != df_input.width[0]]))\nprint(f\"Every image has the same width which is\", df_input.width[0])\n\nprint(f\"Number of images with a different height:\", len(df_input.height[df_input.height != df_input.height[0]]))\nprint(f\"Every image has the same height which is\", df_input.height[0])\n\nprint(f\"We can see that every image has the same shape which is\", imgs[0].shape)\ntarget_shape = imgs[0].shape[0: 2]","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:54:58.81132Z","iopub.execute_input":"2022-07-10T14:54:58.811844Z","iopub.status.idle":"2022-07-10T14:54:58.826536Z","shell.execute_reply.started":"2022-07-10T14:54:58.811797Z","shell.execute_reply":"2022-07-10T14:54:58.82501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display the number of picture in each category\nax = df_input.category.value_counts(sort=False).plot.bar()\nax.set_xlabel('category')\nax.set_ylabel('number of images')\nax.set_title(\"Number of images per category\")\nax.plot()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:54:58.82854Z","iopub.execute_input":"2022-07-10T14:54:58.829505Z","iopub.status.idle":"2022-07-10T14:54:59.148068Z","shell.execute_reply.started":"2022-07-10T14:54:58.829474Z","shell.execute_reply":"2022-07-10T14:54:59.146759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each category has an unbalanced set of images. It is important to know that the neural network will have an unbalanced input. Let's be careful about a category overfitting when training the neural network.","metadata":{}},{"cell_type":"markdown","source":"Look at the pictures for the submission if they have the same format.","metadata":{}},{"cell_type":"code","source":"X_submission = np.load(submission_file, allow_pickle=True)[\"X\"]\nX_submission = X_submission.astype('float32') / 255\n\ntarget_shape = X_submission.shape[1:3]\nX_submission.shape, X_submission.dtype, target_shape\n\nplt.figure(figsize=(15,5))\nfor i in range(15):\n    plt.subplot(3, 5, i + 1)\n    plt.imshow(X_submission[i])\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:24:20.999071Z","iopub.execute_input":"2022-07-10T14:24:20.999476Z","iopub.status.idle":"2022-07-10T14:24:21.67448Z","shell.execute_reply.started":"2022-07-10T14:24:20.999447Z","shell.execute_reply":"2022-07-10T14:24:21.673154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We need to split the set of images into three sets:\n\n    train set: data used to train the model (improve the model accuracy).\n    validation set: test the model accuracy during the training.\n    test set: test the model accuracy after the training.\n\nAs we are going to use a keras.ImageDataGenerator, it will handle the train set, validation set and test set automatically. However, it is still required to split data into two directories:\n\n    Test data will be located in ships_scaled/test. In order to be fair with the test data, we want the same number of images for each category.\n    Train/validation data will be located in ships_scaled/train.\n","metadata":{}},{"cell_type":"code","source":"def setup_data(dir_input, dir_output, label_to_category, nb_test_img_per_category=None):\n    \"\"\"\n    Move some images from an input directory to an output directory\n    \n    Arguments:\n        * dir_input: the input directory\n        * dir_output: the output directory\n        * label_to_category: used to get the category name (thus the directory name)\n        * nb_test_img_per_category: number of images per category\n    \"\"\"\n    for label, class_name in label_to_category.items():\n        class_path = os.path.join(dir_input, class_name)\n        new_class_path = os.path.join(dir_output, class_name)\n        os.mkdir(new_class_path)\n        \n        # if None move everything\n        for filename in os.listdir(class_path)[:nb_test_img_per_category]:\n            os.rename(os.path.join(class_path, filename),\n                      os.path.join(new_class_path, filename))","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:24:21.676272Z","iopub.execute_input":"2022-07-10T14:24:21.677509Z","iopub.status.idle":"2022-07-10T14:24:21.687763Z","shell.execute_reply.started":"2022-07-10T14:24:21.677467Z","shell.execute_reply":"2022-07-10T14:24:21.686376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"setup_data(path_train,\n           path_test,\n           label_to_category,\n           nb_test_img_per_category=200)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:24:21.689859Z","iopub.execute_input":"2022-07-10T14:24:21.691085Z","iopub.status.idle":"2022-07-10T14:24:21.800278Z","shell.execute_reply.started":"2022-07-10T14:24:21.691041Z","shell.execute_reply":"2022-07-10T14:24:21.799025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Data augmentation is a way to improve the dataset as input images are going to be randomly modified. ImageDataGenerators from keras are going to be used. We are going to have two generators a test test_datagen and a train_datagen. The last generator is going to have more work as it is going to be used for the training and we want more diversity in the training set.\n\nMoreover, a pre-trained neural network is going to be used. In this case, input images must all be preprocessed by the same and specific preprocess function for resnet neural network keras.applications.resnet.preprocess_input. An automatic way of preprocessing input images is to give this function to a generator.\n\nThe generators also load data on the fly which, avoid memory issues. Images are saved in directories. Then, the generator will automatically load the image and find its category (from the directory name).\n\nFinally, one of the feature of the generator is to automatically split training data and validation data.\n\nTo recap, the generators will do the following work:\n\n    preprocess input (always)\n    load data on the fly (always)\n    data augmentation (if needed)\n    split training and validation data (if needed)\n\n# ImageDataGenerator for test set\n\nThe test set is here only to test the neural network accuracy. Thus, it is not needed to apply some random modifications to these images meaning data augmentation is not needed. Also, data are not split. The test images will be saved in order to check them after a prediction.\n","metadata":{}},{"cell_type":"code","source":"path_gen_test = \"gen_test\"\n!mkdir gen_test","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:24:21.802106Z","iopub.execute_input":"2022-07-10T14:24:21.80259Z","iopub.status.idle":"2022-07-10T14:24:22.560926Z","shell.execute_reply.started":"2022-07-10T14:24:21.802561Z","shell.execute_reply":"2022-07-10T14:24:22.559247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.resnet import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntest_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\n# Categories are classed in an alphabetical order\ntest_generator = test_datagen.flow_from_directory(\n        path_test,\n        target_size=target_shape,\n        seed=SEED,\n        shuffle=False,\n        save_to_dir=path_gen_test,\n        save_format=\"jpeg\",\n        interpolation=\"bicubic\")","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:24:22.563195Z","iopub.execute_input":"2022-07-10T14:24:22.564013Z","iopub.status.idle":"2022-07-10T14:24:22.793377Z","shell.execute_reply.started":"2022-07-10T14:24:22.563963Z","shell.execute_reply":"2022-07-10T14:24:22.791896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rotation_range=20,\n                                   preprocessing_function=preprocess_input,\n                                   horizontal_flip=True,\n                                   validation_split=0.1)\n\ntrain_generator = train_datagen.flow_from_directory(\n        path_train,\n        target_size=target_shape,\n        batch_size=64,\n        seed=SEED,\n        subset=\"training\",\n        interpolation=\"bicubic\")\n\nvalidation_generator = train_datagen.flow_from_directory(\n        path_train,\n        target_size=target_shape,\n        batch_size=64,\n        seed=SEED,\n        subset=\"validation\",\n        interpolation=\"bicubic\")","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:24:22.795355Z","iopub.execute_input":"2022-07-10T14:24:22.795799Z","iopub.status.idle":"2022-07-10T14:24:26.467524Z","shell.execute_reply.started":"2022-07-10T14:24:22.795759Z","shell.execute_reply":"2022-07-10T14:24:26.464971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Creation\n\nFor this competition, it is required to use a problem solving technique called transfer learning. It focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. The generic problem is images classification. Our related problem is ship classification.\n\nIn this notebook, we are going to use a pre-trained convolutional neural network (CNN) model and add on the top of it some custom layers. The transfer of learning comes from the pre-trained CNN model. The knowledge of the pre-trained model will be features maps. Features maps are the output of several consecutive convolutions. Each features map contains an information that will be processed by the outer layers.\n\nThis model (ResNet50) is light in terms of computation. As a result, the training time with this model was reasonable and the predictions were quite accurate as it can be seen below.\n","metadata":{}},{"cell_type":"code","source":"input_shape = (target_shape[0], target_shape[1], 3) # meme forme\ninput_shape","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:24:26.469808Z","iopub.execute_input":"2022-07-10T14:24:26.470727Z","iopub.status.idle":"2022-07-10T14:24:26.480068Z","shell.execute_reply.started":"2022-07-10T14:24:26.470679Z","shell.execute_reply":"2022-07-10T14:24:26.478676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\n\nmodel_resnet50 = ResNet50(include_top=False,\n                          weights=\"imagenet\",\n                          input_shape=input_shape,\n                          pooling='max')","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:24:26.482489Z","iopub.execute_input":"2022-07-10T14:24:26.483523Z","iopub.status.idle":"2022-07-10T14:24:34.885566Z","shell.execute_reply.started":"2022-07-10T14:24:26.483466Z","shell.execute_reply":"2022-07-10T14:24:34.884285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of layers : \", len(model_resnet50.layers))\nmodel_resnet50.summary()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-10T14:36:27.209465Z","iopub.execute_input":"2022-07-10T14:36:27.209887Z","iopub.status.idle":"2022-07-10T14:36:27.250313Z","shell.execute_reply.started":"2022-07-10T14:36:27.209844Z","shell.execute_reply":"2022-07-10T14:36:27.248935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization\n\nmodel_custom = Sequential(name='custom_model')\nmodel_custom.add(Input(shape=model_resnet50.output.shape[1:]))\nmodel_custom.add(BatchNormalization(name='custom_bn'))\nmodel_custom.add(Dense(len(label_to_category), activation='softmax'))\n\n\nprint(\"Number of layers :\", len(model_custom.layers))\nmodel_custom.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:24:34.930636Z","iopub.execute_input":"2022-07-10T14:24:34.931689Z","iopub.status.idle":"2022-07-10T14:24:34.973882Z","shell.execute_reply.started":"2022-07-10T14:24:34.931647Z","shell.execute_reply":"2022-07-10T14:24:34.972498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\nmodel = Sequential([model_resnet50, model_custom])\n\nprint(\"Number of layers : \", len(model.get_layer(name='resnet50').layers) + len(model.get_layer(name='custom_model').layers))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:24:34.975836Z","iopub.execute_input":"2022-07-10T14:24:34.976461Z","iopub.status.idle":"2022-07-10T14:24:35.497281Z","shell.execute_reply.started":"2022-07-10T14:24:34.976421Z","shell.execute_reply":"2022-07-10T14:24:35.495734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training\nThe model is simply trained with the training and validation data.\n\nFor the Optimizer, the Adam optimizer is going to be used because it seems to be the most efficient.\n\nTwo callbacks are also used to make the training more convenient. The first callback saves the best weights. Indeed, during the training, the accuracy might vary. Therefore, we want to save the best weights throughout the training. At the end of training, the best weights (with the greatest validation accuracy) are loaded into the model. The second callback stops the training when the validation accuracy has not improved for 5 times in a row. This is useful to not waste training time when it is not needed.\n\nThere are two training steps. The first step is to only train the layers in the custom on the top model. The ResNet50 layers are frozen. The features maps from ResNet50 already give great information to classify ships. During this step, 70% of validation accuracy is reached. We can also notice a dense is actually enough which confirm the efficiency of ResNet50. Then, a second training is performed. This time, the whole model (the ResNet50 model and the custom model) is trainable. During this second step, the learning is very low because it is a step of fine tuning. The weights of the ResNet50 model should only be slightly modified.","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate=0.0001), \n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:24:35.500423Z","iopub.execute_input":"2022-07-10T14:24:35.501301Z","iopub.status.idle":"2022-07-10T14:24:35.522162Z","shell.execute_reply.started":"2022-07-10T14:24:35.501238Z","shell.execute_reply":"2022-07-10T14:24:35.520623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze the model\nmodel_resnet50.trainable = False\n# Freeze the BatchNormalization of model custom\nmodel_custom.get_layer('custom_bn').trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:24:35.524565Z","iopub.execute_input":"2022-07-10T14:24:35.525149Z","iopub.status.idle":"2022-07-10T14:24:35.540465Z","shell.execute_reply.started":"2022-07-10T14:24:35.525074Z","shell.execute_reply":"2022-07-10T14:24:35.539017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Callbacks","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import EarlyStopping\n\ncheckpoint_filepath = 'model_checkpoint'\nmodel_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath,\n                                            save_weights_only=True,\n                                            monitor='val_accuracy',\n                                            mode='max',\n                                            save_best_only=True,\n                                            verbose=1)\n\nmodel_earlystop_callback = EarlyStopping(monitor='val_accuracy',\n                                         patience=5,\n                                         verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:24:35.542133Z","iopub.execute_input":"2022-07-10T14:24:35.54335Z","iopub.status.idle":"2022-07-10T14:24:35.556049Z","shell.execute_reply.started":"2022-07-10T14:24:35.543291Z","shell.execute_reply":"2022-07-10T14:24:35.554839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train","metadata":{}},{"cell_type":"code","source":"nb_epochs = 10\n\n# Model weights are saved at the end of every epoch, if it is the best seen\n# so far.\nmodel_history = model.fit(x=train_generator,\n                          epochs=nb_epochs,\n                          verbose=1,\n                          validation_data=validation_generator,\n                          callbacks=[model_checkpoint_callback, model_earlystop_callback]\n)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-10T14:24:35.55796Z","iopub.execute_input":"2022-07-10T14:24:35.558722Z","iopub.status.idle":"2022-07-10T14:35:49.59644Z","shell.execute_reply.started":"2022-07-10T14:24:35.558678Z","shell.execute_reply":"2022-07-10T14:35:49.595003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unfreeze the layers resnet50\nmodel_resnet50.trainable = True\n# Unfreeze the BatchNormalization of the model custom\nmodel_custom.get_layer('custom_bn').trainable = True\n\n# low learning rate\nmodel.compile(optimizer=Adam(learning_rate=1e-5), \n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:35:49.59861Z","iopub.execute_input":"2022-07-10T14:35:49.599143Z","iopub.status.idle":"2022-07-10T14:35:49.665592Z","shell.execute_reply.started":"2022-07-10T14:35:49.599042Z","shell.execute_reply":"2022-07-10T14:35:49.664162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_epochs_tuning = 20\n\nmodel_history_tunning = model.fit(x=train_generator,\n                                  epochs=nb_epochs_tuning,\n                                  verbose=1,\n                                  validation_data=validation_generator,\n                                  callbacks=[model_checkpoint_callback, model_earlystop_callback]\n)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-07-10T14:39:02.34331Z","iopub.execute_input":"2022-07-10T14:39:02.343703Z","iopub.status.idle":"2022-07-10T14:53:42.861273Z","shell.execute_reply.started":"2022-07-10T14:39:02.343673Z","shell.execute_reply":"2022-07-10T14:53:42.859958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check training results\n\nIt is now time to see the result of the training steps. History of the training is put in a DataFrame. Then, we plot the train accuracy and validation accuracy over epochs.","metadata":{}},{"cell_type":"code","source":"hist_custom_df = pd.DataFrame(model_history.history) \nhist_tuning_df = pd.DataFrame(model_history_tunning.history) \nhist_df = pd.concat([hist_custom_df, hist_tuning_df])\nhist_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:53:42.86417Z","iopub.execute_input":"2022-07-10T14:53:42.864641Z","iopub.status.idle":"2022-07-10T14:53:42.882371Z","shell.execute_reply.started":"2022-07-10T14:53:42.864597Z","shell.execute_reply":"2022-07-10T14:53:42.880971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_df.tail()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:53:42.884665Z","iopub.execute_input":"2022-07-10T14:53:42.88549Z","iopub.status.idle":"2022-07-10T14:53:42.905896Z","shell.execute_reply.started":"2022-07-10T14:53:42.885448Z","shell.execute_reply":"2022-07-10T14:53:42.904458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(hist_df.accuracy.to_numpy())\nplt.plot(hist_df.val_accuracy.to_numpy())\nplt.title('Model accuracy over epochs')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.xlim([0, hist_df.index.size])\nplt.axvline(x=nb_epochs, color='green')\nplt.legend(['train accuracy', 'validation accuracy', 'fine-tuning time'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:53:42.909585Z","iopub.execute_input":"2022-07-10T14:53:42.910587Z","iopub.status.idle":"2022-07-10T14:54:02.585487Z","shell.execute_reply.started":"2022-07-10T14:53:42.910545Z","shell.execute_reply":"2022-07-10T14:54:02.584162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the best model\nmodel.load_weights(checkpoint_filepath)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:54:02.586999Z","iopub.execute_input":"2022-07-10T14:54:02.587761Z","iopub.status.idle":"2022-07-10T14:54:04.1367Z","shell.execute_reply.started":"2022-07-10T14:54:02.587718Z","shell.execute_reply":"2022-07-10T14:54:04.13521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = model.evaluate(test_generator)\nprint(\"The model accuracy over the test data %.2f%%\"%(metrics[1] * 100))","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:54:04.138651Z","iopub.execute_input":"2022-07-10T14:54:04.139078Z","iopub.status.idle":"2022-07-10T14:54:09.330723Z","shell.execute_reply.started":"2022-07-10T14:54:04.139035Z","shell.execute_reply":"2022-07-10T14:54:09.329195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(filepath=\"output_model\")","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:54:09.333064Z","iopub.execute_input":"2022-07-10T14:54:09.33352Z","iopub.status.idle":"2022-07-10T14:54:47.830919Z","shell.execute_reply.started":"2022-07-10T14:54:09.333475Z","shell.execute_reply":"2022-07-10T14:54:47.829555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confusion Matrix\n\nA confusion matrix usage is to evaluate the quality of the output of a classifier. The diagonal elements represent the number of points for which the predicted label is equal to the true label, while off-diagonal elements are those that are mislabeled by the classifier. The higher the diagonal values of the confusion matrix the better, indicating many correct predictions.\n\nThe true labels are represented by the rows and the predictions by the columns.","metadata":{}},{"cell_type":"code","source":"def my_plot_confusion_matrix(conf_matrix, classes, title=None):\n    df_cm = pd.DataFrame(conf_matrix, classes, classes)\n    plt.figure(figsize=(10,5))\n    sn.set(font_scale=1.4) # taille des labels\n    sn.heatmap(df_cm, cmap='Oranges', fmt='g', annot=True, annot_kws={\"size\": 11}) # font size\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    if title:\n        plt.title(title)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:54:47.846087Z","iopub.execute_input":"2022-07-10T14:54:47.846439Z","iopub.status.idle":"2022-07-10T14:54:47.854013Z","shell.execute_reply.started":"2022-07-10T14:54:47.846402Z","shell.execute_reply":"2022-07-10T14:54:47.852612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n# confusion matrix\ny_pred = model.predict(test_generator).argmax(axis=1)\nconf_matrix = confusion_matrix(test_generator.classes, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:54:47.855945Z","iopub.execute_input":"2022-07-10T14:54:47.856749Z","iopub.status.idle":"2022-07-10T14:54:52.163739Z","shell.execute_reply.started":"2022-07-10T14:54:47.856709Z","shell.execute_reply":"2022-07-10T14:54:52.161735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_plot_confusion_matrix(conf_matrix, label_to_category.values(), title=\"Confusion matrix from the model prediction\")","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:54:52.16996Z","iopub.execute_input":"2022-07-10T14:54:52.172922Z","iopub.status.idle":"2022-07-10T14:54:53.270523Z","shell.execute_reply.started":"2022-07-10T14:54:52.172875Z","shell.execute_reply":"2022-07-10T14:54:53.269163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The confusion matrix looks great. Most of the values are on the diagonal. The model has one main difficulty. It mixes smallfish and vsmallfish up. That is understandable as these two kind of ships look alike.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(test_generator.classes, y_pred, target_names=label_to_category.values()))","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:54:53.272299Z","iopub.execute_input":"2022-07-10T14:54:53.273711Z","iopub.status.idle":"2022-07-10T14:54:53.293548Z","shell.execute_reply.started":"2022-07-10T14:54:53.273667Z","shell.execute_reply":"2022-07-10T14:54:53.292207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All the scores are close to 1 besides the vsmallfish and smallfish as it could be seen from the confusion matrix.","metadata":{}},{"cell_type":"markdown","source":"# Submission\n\nIn this part, the submission to the competition is made. The submission images are loaded from the ships_competition.npy file. Then, the model predicts the category of the images. The result is stored in a CSV file. This CSV file is the submission file.","metadata":{}},{"cell_type":"code","source":"X_submission = np.load(submission_file, allow_pickle=True)[\"X\"]\nX_submission_1 = X_submission.astype(float)/255\nX_submission = preprocess_input(X_submission.astype(float))\nX_submission.shape, X_submission.dtype","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:54:53.295584Z","iopub.execute_input":"2022-07-10T14:54:53.296063Z","iopub.status.idle":"2022-07-10T14:54:53.372809Z","shell.execute_reply.started":"2022-07-10T14:54:53.296024Z","shell.execute_reply":"2022-07-10T14:54:53.371292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check that the data are ok and the predict seems ok\nplt.figure(figsize=(15,5))\nX = X_submission\npred = model.predict(X)\nfor i in range(15):\n    plt.subplot(3, 5, i + 1)\n    plt.title(label_to_category[pred[i].argmax()])\n    plt.imshow(X[i])\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:54:53.374724Z","iopub.execute_input":"2022-07-10T14:54:53.375171Z","iopub.status.idle":"2022-07-10T14:54:56.544787Z","shell.execute_reply.started":"2022-07-10T14:54:53.375101Z","shell.execute_reply":"2022-07-10T14:54:56.543645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_submission).argmax(axis=1)\ndf = pd.DataFrame({\"Category\":y_pred})\ndf.to_csv(\"submission.csv\", index_label=\"Id\")","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:54:56.546852Z","iopub.execute_input":"2022-07-10T14:54:56.548105Z","iopub.status.idle":"2022-07-10T14:54:57.919609Z","shell.execute_reply.started":"2022-07-10T14:54:56.547895Z","shell.execute_reply":"2022-07-10T14:54:57.918235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:54:57.92141Z","iopub.execute_input":"2022-07-10T14:54:57.921894Z","iopub.status.idle":"2022-07-10T14:54:57.9298Z","shell.execute_reply.started":"2022-07-10T14:54:57.92185Z","shell.execute_reply":"2022-07-10T14:54:57.928469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!head submission.csv","metadata":{"execution":{"iopub.status.busy":"2022-07-10T14:54:57.931965Z","iopub.execute_input":"2022-07-10T14:54:57.932899Z","iopub.status.idle":"2022-07-10T14:54:58.807508Z","shell.execute_reply.started":"2022-07-10T14:54:57.932857Z","shell.execute_reply":"2022-07-10T14:54:58.805892Z"},"trusted":true},"execution_count":null,"outputs":[]}]}